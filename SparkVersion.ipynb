{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pyspark.sql.functions as functions\n",
    "from pyspark.sql.functions import unix_timestamp\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import DateType\n",
    "from functools import *\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import col, expr, when\n",
    "import math\n",
    "from geopy import distance\n",
    "import networkx as nx\n",
    "import datetime\n",
    "from datetime import timezone\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_date = datetime.date(2017, 9, 13)\n",
    "end_date = datetime.date(2017, 9, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"2017-09/*.csv\"\n",
    "station_path = \"metadata/BFKOORD_GEO\"\n",
    "BPUIC = []\n",
    "long = []\n",
    "lat = []\n",
    "name = []\n",
    "zurich_coord = (47.407665036,8.540331172)\n",
    "MAX_DIST = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.90.38.21:4046\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.2.0.2.6.4.0-91</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>project-mbanga</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=yarn appName=project-mbanga>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import getpass\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = pyspark.conf.SparkConf()\n",
    "conf.setMaster('yarn')\n",
    "conf.setAppName('project-{0}'.format(getpass.getuser()))\n",
    "conf.set('spark.executor.memory', '4g')\n",
    "conf.set('spark.executor.instances', '6')\n",
    "conf.set('spark.port.maxRetries', '100')\n",
    "sc = pyspark.SparkContext.getOrCreate(conf)\n",
    "conf = sc.getConf()\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#r = pd.read_pickle('september')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"/home/mbanga/BFKOORD_GEO\"\n",
    "station_file = open(path,'r')\n",
    "\n",
    "\n",
    "for line in station_file:\n",
    "    l = line.split()\n",
    "    BPUIC.append(l[0])\n",
    "    long.append(l[1])\n",
    "    lat.append(l[2])\n",
    "    name.append(l[5])\n",
    "    \n",
    "d = {'BPUIC':BPUIC,\n",
    "     'longitude' : long,\n",
    "     'latitude' : lat,}\n",
    "\n",
    "station_df = pd.DataFrame(d)\n",
    "station_df = station_df[['BPUIC','longitude','latitude']]\n",
    "station_df['BPUIC'] = station_df['BPUIC'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BPUIC</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>26.074412</td>\n",
       "      <td>44.446770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1.811446</td>\n",
       "      <td>50.901549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1.075329</td>\n",
       "      <td>51.284212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>-3.543547</td>\n",
       "      <td>50.729172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>9.733756</td>\n",
       "      <td>46.922368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BPUIC  longitude   latitude\n",
       "0      2  26.074412  44.446770\n",
       "1      3   1.811446  50.901549\n",
       "2      4   1.075329  51.284212\n",
       "3      5  -3.543547  50.729172\n",
       "4      7   9.733756  46.922368"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_station = spark.createDataFrame(station_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+---------+\n",
      "|BPUIC|longitude| latitude|\n",
      "+-----+---------+---------+\n",
      "|    2|26.074412|44.446770|\n",
      "|    3| 1.811446|50.901549|\n",
      "|    4| 1.075329|51.284212|\n",
      "|    5|-3.543547|50.729172|\n",
      "|    7| 9.733756|46.922368|\n",
      "|    8| 8.571251|50.051219|\n",
      "|    9|18.643803|54.355520|\n",
      "|   11| 7.389462|47.191804|\n",
      "|   13|29.019602|40.996348|\n",
      "|   17| 9.873959|48.577852|\n",
      "|   19| 4.786044|43.921937|\n",
      "|   21| 2.140369|41.378914|\n",
      "|   22| 7.589551|47.547405|\n",
      "|   24| 7.395229|46.937482|\n",
      "|   27|-1.899480|52.483627|\n",
      "|   28| 6.838953|46.949588|\n",
      "|   29|17.106466|48.158910|\n",
      "|   31| 4.335694|50.835376|\n",
      "|   34|-2.979650|53.404289|\n",
      "|   35| 8.500049|47.114619|\n",
      "+-----+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_station.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_distance(latitude,longitude):\n",
    "    coord = (latitude,longitude)\n",
    "    print(latitude)\n",
    "    if(latitude == \"null\" or longitude == \"null\"):\n",
    "        return False\n",
    "    else:\n",
    "        distance_ = distance.distance(zurich_coord,coord).km\n",
    "        return distance_ < MAX_DIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import timedelta, date\n",
    "def daterange(start_date, end_date):\n",
    "    for n in range(int ((end_date - start_date).days)):\n",
    "        yield start_date + timedelta(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_hdfs_file_path = 'hdfs://iccluster045.iccluster.epfl.ch:8020/datasets/project/istdaten/'\n",
    "end_hdfs_file_path = 'istdaten.csv'\n",
    "slash = '/'\n",
    "\n",
    "r = pd.DataFrame()\n",
    "for single_date in daterange(start_date, end_date):\n",
    "        read_path = start_hdfs_file_path + str(single_date.year) + slash + str(single_date.month).zfill(2) + slash\n",
    "        read_path += single_date.strftime(\"%Y-%m-%d\") + end_hdfs_file_path\n",
    "\n",
    "        df = spark.read.csv(read_path, sep=';',header=True) \n",
    "        df = df.select(col(\"BETRIEBSTAG\").alias(\"trip_date\"), col(\"FAHRT_BEZEICHNER\").alias(\"trip_id\")\n",
    "                  , col(\"BETREIBER_ID\").alias(\"operator_id\"), col(\"BETREIBER_ABK\").alias(\"operator_abk\")\n",
    "                  , col(\"BETREIBER_NAME\").alias(\"operator_name\"), col(\"PRODUKT_ID\").alias(\"product_id\"), col(\"LINIEN_ID\").alias(\"line_id\")\n",
    "                  , col(\"LINIEN_TEXT\").alias(\"line_text\"), col(\"UMLAUF_ID\").alias(\"circulation_id\"), col(\"VERKEHRSMITTEL_TEXT\").alias(\"transport_text\")\n",
    "                  , col(\"ZUSATZFAHRT_TF\").alias(\"additional_trip\"), col(\"FAELLT_AUS_TF\").alias(\"failed\"), col(\"BPUIC\").alias(\"BPUIC\")\n",
    "                  , col(\"HALTESTELLEN_NAME\").alias(\"stop_name\"), col(\"ANKUNFTSZEIT\").alias(\"scheduled_arrival_time\"), col(\"AN_PROGNOSE\").alias(\"actual_arrival_time\")\n",
    "                  , col(\"AN_PROGNOSE_STATUS\").alias(\"actual_arrival_time_status\"), col(\"ABFAHRTSZEIT\").alias(\"scheduled_departure_time\"), col(\"AB_PROGNOSE\").alias(\"actual_departure_time\")\n",
    "                  , col(\"AB_PROGNOSE_STATUS\").alias(\"actual_departure_time_status\"), col(\"DURCHFAHRT_TF\").alias(\"no_stop\"))\n",
    "\n",
    "        df = df.join(df_station,['BPUIC'],\"outer\")\n",
    "\n",
    "        filter_udf = udf(clean_distance)\n",
    "        df = df.withColumn(\"distance\",filter_udf(df.latitude,df.longitude))\n",
    "        g = df.filter(df.distance==True)\n",
    "        \n",
    "        r = g.toPandas()\n",
    "        r.to_pickle('original_dfs/'+str(single_date))\n",
    "        #r.to_csv(save_path, compression='gzip')\n",
    "        #to_concat = g.toPandas()\n",
    "        #r = pd.concat([r, to_concat], axis=0)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "#print(sys.getsizeof(r) / float(10**6), 'MB')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
